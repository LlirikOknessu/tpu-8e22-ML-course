{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.18.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "import datetime\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    " %reload_ext tensorboard\n",
    "from tensorflow.keras import Model\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 128\n",
    "LEARNING_RATE = 0.05\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "input_dir = Path('./data/prepared')\n",
    "logs_path = Path('./data/logs')\n",
    "if logs_path.exists():\n",
    "  shutil.rmtree(logs_path)\n",
    "logs_path.mkdir(parents=True)\n",
    "\n",
    "X_train_name = input_dir / 'X_train.csv'\n",
    "y_train_name = input_dir / 'y_train.csv'\n",
    "X_test_name = input_dir / 'X_test.csv'\n",
    "y_test_name = input_dir / 'y_test.csv'\n",
    "\n",
    "X_train = pd.read_csv(X_train_name)\n",
    "y_train = pd.read_csv(y_train_name)\n",
    "X_test = pd.read_csv(X_test_name)\n",
    "y_test = pd.read_csv(y_test_name)\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (X_train, y_train)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(436, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=(TensorSpec(shape=(None, 8), dtype=tf.int64, name=None), TensorSpec(shape=(None, 1), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "class SomeModel(Model):\n",
    "    def __init__(self, neurons_cnt=128, **kwargs):\n",
    "        super(SomeModel, self).__init__(**kwargs)\n",
    "        self.neurons_cnt = neurons_cnt  # Сохраняем значение параметра для конфигурации\n",
    "        self.d_in = Dense(8, activation='relu')\n",
    "        self.d1 = Dense(neurons_cnt, activation='relu')\n",
    "        self.d2 = Dense(neurons_cnt, activation='relu')\n",
    "        self.d_out = Dense(1)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.d_in(x)\n",
    "        x = self.d1(x)\n",
    "        x = self.d2(x)\n",
    "        return self.d_out(x)\n",
    "\n",
    "    def get_config(self):\n",
    "        # Возвращаем параметры модели, включая кастомные\n",
    "        config = super(SomeModel, self).get_config()\n",
    "        config.update({\n",
    "            \"neurons_cnt\": self.neurons_cnt  # Добавляем кастомный параметр в конфигурацию\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        # Создаём экземпляр класса из конфигурации\n",
    "        return cls(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ru-lo\\PycharmProjects\\tpu-8e21-ai-basis\\venv\\Lib\\site-packages\\keras\\src\\layers\\layer.py:391: UserWarning: `build()` was called on layer 'some_model_6', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the model\n",
    "model = SomeModel(neurons_cnt=64)\n",
    "model.build(input_shape=(None, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.MeanSquaredError()\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.MeanAbsoluteError(name='train_mae')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.MeanAbsoluteError(name='test_mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(input_vector, labels):\n",
    "  with tf.GradientTape() as tape:\n",
    "    # training=True is only needed if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "    predictions = model(input_vector, training=True)\n",
    "    loss = loss_object(labels, predictions)\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "  train_loss(loss)\n",
    "  train_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(input_vector, labels):\n",
    "  # training=False is only needed if there are layers with different\n",
    "  # behavior during training versus inference (e.g. Dropout).\n",
    "  predictions = model(input_vector, training=False)\n",
    "  t_loss = loss_object(labels, predictions)\n",
    "\n",
    "  test_loss(t_loss)\n",
    "  test_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Trace already enabled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Trace already enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6362075805664062, Accuracy: 0.603752613067627, Test Loss: 0.6878835558891296, Test MAE: 0.5995654463768005\n",
      "Epoch 2, Loss: 0.5787534117698669, Accuracy: 0.5696507096290588, Test Loss: 0.7337146401405334, Test MAE: 0.5701504349708557\n",
      "Epoch 3, Loss: 0.5713530778884888, Accuracy: 0.5627707242965698, Test Loss: 0.6975072622299194, Test MAE: 0.5809425115585327\n",
      "Epoch 4, Loss: 0.5715385675430298, Accuracy: 0.5714064836502075, Test Loss: 0.9550483226776123, Test MAE: 0.6408940553665161\n",
      "Epoch 5, Loss: 0.6469525098800659, Accuracy: 0.5931909680366516, Test Loss: 0.6891505718231201, Test MAE: 0.5929657816886902\n",
      "Epoch 6, Loss: 0.6046574711799622, Accuracy: 0.5864913463592529, Test Loss: 0.6879726648330688, Test MAE: 0.6031933426856995\n",
      "Epoch 7, Loss: 0.5803183913230896, Accuracy: 0.5739027261734009, Test Loss: 0.7313417792320251, Test MAE: 0.5702424645423889\n",
      "Epoch 8, Loss: 0.5844343304634094, Accuracy: 0.5744612216949463, Test Loss: 0.7184798121452332, Test MAE: 0.5716366767883301\n",
      "Epoch 9, Loss: 0.5866389870643616, Accuracy: 0.5781055688858032, Test Loss: 0.714421272277832, Test MAE: 0.5729397535324097\n",
      "Epoch 10, Loss: 0.6019189953804016, Accuracy: 0.5772368907928467, Test Loss: 0.688605785369873, Test MAE: 0.5948006510734558\n",
      "Epoch 11, Loss: 0.5753417015075684, Accuracy: 0.5670598745346069, Test Loss: 0.6948343515396118, Test MAE: 0.6250345706939697\n",
      "Epoch 12, Loss: 0.5720323920249939, Accuracy: 0.5714089870452881, Test Loss: 0.7318811416625977, Test MAE: 0.5702213048934937\n",
      "Epoch 13, Loss: 0.6269300580024719, Accuracy: 0.5942944288253784, Test Loss: 0.7032600045204163, Test MAE: 0.6403359174728394\n",
      "Epoch 14, Loss: 0.6310603022575378, Accuracy: 0.6086908578872681, Test Loss: 0.692435622215271, Test MAE: 0.619254469871521\n",
      "Epoch 15, Loss: 0.5737290978431702, Accuracy: 0.5727041363716125, Test Loss: 0.6889210939407349, Test MAE: 0.5936793684959412\n",
      "Epoch 16, Loss: 0.5920984148979187, Accuracy: 0.587369441986084, Test Loss: 0.6921482086181641, Test MAE: 0.5866677165031433\n",
      "Epoch 17, Loss: 0.6294206380844116, Accuracy: 0.5995110273361206, Test Loss: 0.7810614109039307, Test MAE: 0.5737014412879944\n",
      "Epoch 18, Loss: 0.6546763777732849, Accuracy: 0.6214408278465271, Test Loss: 0.8593341112136841, Test MAE: 0.5997303128242493\n",
      "Epoch 19, Loss: 0.6523576974868774, Accuracy: 0.6244952082633972, Test Loss: 0.707603931427002, Test MAE: 0.575517475605011\n",
      "Epoch 20, Loss: 0.5778995752334595, Accuracy: 0.5747379660606384, Test Loss: 0.6879255175590515, Test MAE: 0.6025782227516174\n",
      "Epoch 21, Loss: 0.6488572955131531, Accuracy: 0.617641806602478, Test Loss: 0.7546130418777466, Test MAE: 0.5704872012138367\n",
      "Epoch 22, Loss: 0.6228502988815308, Accuracy: 0.5914282202720642, Test Loss: 0.8337165117263794, Test MAE: 0.7603641152381897\n",
      "Epoch 23, Loss: 0.6305885314941406, Accuracy: 0.6155270338058472, Test Loss: 0.6891233921051025, Test MAE: 0.6096984148025513\n",
      "Epoch 24, Loss: 0.5647540092468262, Accuracy: 0.5676664113998413, Test Loss: 0.7072979211807251, Test MAE: 0.5756429433822632\n",
      "Epoch 25, Loss: 0.5916365385055542, Accuracy: 0.5803222060203552, Test Loss: 0.689433217048645, Test MAE: 0.5921691060066223\n",
      "Epoch 26, Loss: 0.6931890845298767, Accuracy: 0.6386924386024475, Test Loss: 0.8192969560623169, Test MAE: 0.5842355489730835\n",
      "Epoch 27, Loss: 0.6111797094345093, Accuracy: 0.591606855392456, Test Loss: 0.6940959692001343, Test MAE: 0.6233211755752563\n",
      "Epoch 28, Loss: 0.6436688303947449, Accuracy: 0.6166195869445801, Test Loss: 0.7068771123886108, Test MAE: 0.5758170485496521\n",
      "Epoch 29, Loss: 0.5866785645484924, Accuracy: 0.5672222375869751, Test Loss: 0.7038458585739136, Test MAE: 0.577242374420166\n",
      "Epoch 30, Loss: 0.5875329375267029, Accuracy: 0.5787392258644104, Test Loss: 0.6924057602882385, Test MAE: 0.5862547159194946\n",
      "Epoch 31, Loss: 0.5920705795288086, Accuracy: 0.5872984528541565, Test Loss: 0.6901385188102722, Test MAE: 0.6130942702293396\n",
      "Epoch 32, Loss: 0.5983042120933533, Accuracy: 0.5856803059577942, Test Loss: 0.7791405320167542, Test MAE: 0.5732855200767517\n",
      "Epoch 33, Loss: 0.655920684337616, Accuracy: 0.6135686635971069, Test Loss: 0.7098144888877869, Test MAE: 0.6497960090637207\n",
      "Epoch 34, Loss: 0.6275261044502258, Accuracy: 0.6008477807044983, Test Loss: 0.8487393856048584, Test MAE: 0.5954691171646118\n",
      "Epoch 35, Loss: 0.6030235886573792, Accuracy: 0.5786340236663818, Test Loss: 0.716029167175293, Test MAE: 0.6578558087348938\n",
      "Epoch 36, Loss: 0.5817957520484924, Accuracy: 0.5814794898033142, Test Loss: 0.8118327260017395, Test MAE: 0.5820096135139465\n",
      "Epoch 37, Loss: 0.6360050439834595, Accuracy: 0.6002742052078247, Test Loss: 0.7584341764450073, Test MAE: 0.5706067681312561\n",
      "Epoch 38, Loss: 0.618310809135437, Accuracy: 0.5985649228096008, Test Loss: 0.7015374302864075, Test MAE: 0.5784862041473389\n",
      "Epoch 39, Loss: 0.5882441401481628, Accuracy: 0.5793694257736206, Test Loss: 0.7878878116607666, Test MAE: 0.5754190683364868\n",
      "Epoch 40, Loss: 0.5916966795921326, Accuracy: 0.5798419713973999, Test Loss: 0.7301445603370667, Test MAE: 0.5702897906303406\n",
      "Epoch 41, Loss: 0.6178876757621765, Accuracy: 0.5925896763801575, Test Loss: 0.6967380046844482, Test MAE: 0.5814666748046875\n",
      "Epoch 42, Loss: 0.5765525102615356, Accuracy: 0.5685220956802368, Test Loss: 0.6898022890090942, Test MAE: 0.5912300944328308\n",
      "Epoch 43, Loss: 0.5749886631965637, Accuracy: 0.5662684440612793, Test Loss: 0.6920868158340454, Test MAE: 0.6183921694755554\n",
      "Epoch 44, Loss: 0.5857172608375549, Accuracy: 0.5787410140037537, Test Loss: 0.6930728554725647, Test MAE: 0.5852962732315063\n",
      "Epoch 45, Loss: 0.5859689712524414, Accuracy: 0.5792905688285828, Test Loss: 0.7188981175422668, Test MAE: 0.5715195536613464\n",
      "Epoch 46, Loss: 0.6217129826545715, Accuracy: 0.602677047252655, Test Loss: 0.7386412024497986, Test MAE: 0.5701034665107727\n",
      "Epoch 47, Loss: 0.5759196877479553, Accuracy: 0.5667394995689392, Test Loss: 0.6903557777404785, Test MAE: 0.6137240529060364\n",
      "Epoch 48, Loss: 0.606172502040863, Accuracy: 0.5867591500282288, Test Loss: 0.7168864011764526, Test MAE: 0.5720912218093872\n",
      "Epoch 49, Loss: 0.5716391801834106, Accuracy: 0.565564751625061, Test Loss: 0.6879096031188965, Test MAE: 0.602321207523346\n",
      "Epoch 50, Loss: 0.5940455794334412, Accuracy: 0.5848969221115112, Test Loss: 0.6897866725921631, Test MAE: 0.6120245456695557\n",
      "WARNING:tensorflow:Ignoring `profiler_outdir` passed to trace_export(). Please pass it to trace_on() instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Ignoring `profiler_outdir` passed to trace_export(). Please pass it to trace_on() instead.\n"
     ]
    },
    {
     "ename": "UnavailableError",
     "evalue": "Cannot export profiling results. No profiler is running.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnavailableError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[90], line 47\u001b[0m\n\u001b[0;32m     44\u001b[0m   test_accuracy\u001b[38;5;241m.\u001b[39mreset_state()\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m fit_summary_writer\u001b[38;5;241m.\u001b[39mas_default():\n\u001b[1;32m---> 47\u001b[0m   \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace_export\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmy_func_trace\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m      \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m      \u001b[49m\u001b[43mprofiler_outdir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlogdir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\tpu-8e21-ai-basis\\venv\\Lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1433\u001b[0m, in \u001b[0;36mtrace_export\u001b[1;34m(name, step, profiler_outdir)\u001b[0m\n\u001b[0;32m   1428\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m profiler_outdir:\n\u001b[0;32m   1429\u001b[0m     logging\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1430\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIgnoring `profiler_outdir` passed to trace_export(). Please pass it\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1431\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m to trace_on() instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1432\u001b[0m     )\n\u001b[1;32m-> 1433\u001b[0m   \u001b[43m_profiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1435\u001b[0m trace_off()\n",
      "File \u001b[1;32m~\\PycharmProjects\\tpu-8e21-ai-basis\\venv\\Lib\\site-packages\\tensorflow\\python\\profiler\\profiler_v2.py:144\u001b[0m, in \u001b[0;36mstop\u001b[1;34m(save)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _profiler_lock:\n\u001b[0;32m    143\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m _profiler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mUnavailableError(\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    146\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot export profiling results. No profiler is running.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    147\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m save:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mUnavailableError\u001b[0m: Cannot export profiling results. No profiler is running."
     ]
    }
   ],
   "source": [
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_log_dir = logs_path / 'gradient_tape' / current_time / 'train'\n",
    "train_log_dir.mkdir(exist_ok=True, parents=True)\n",
    "test_log_dir = logs_path / 'gradient_tape' / current_time / 'test'\n",
    "test_log_dir.mkdir(exist_ok=True, parents=True)\n",
    "train_summary_writer = tf.summary.create_file_writer(str(train_log_dir))\n",
    "test_summary_writer = tf.summary.create_file_writer(str(test_log_dir))\n",
    "\n",
    "logdir=logs_path / \"fit\" / datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "logdir.mkdir(exist_ok=True, parents=True)\n",
    "fit_summary_writer = tf.summary.create_file_writer(str(logdir))\n",
    "\n",
    "tf.summary.trace_on(graph=True, profiler=True, profiler_outdir=str(logdir))\n",
    "for epoch in range(EPOCHS):\n",
    "  # Reset the metrics at the start of the next epoch\n",
    "  for (x_train, y_train) in train_ds:\n",
    "\n",
    "    with fit_summary_writer.as_default():\n",
    "      train_step(x_train, y_train)\n",
    "\n",
    "\n",
    "  with train_summary_writer.as_default():\n",
    "    tf.summary.scalar('loss', train_loss.result(), step=epoch)\n",
    "    tf.summary.scalar('accuracy', train_accuracy.result(), step=epoch)\n",
    "\n",
    "  for (x_test, y_test) in test_ds:\n",
    "    test_step(x_test, y_test)\n",
    "\n",
    "  with test_summary_writer.as_default():\n",
    "    tf.summary.scalar('loss', test_loss.result(), step=epoch)\n",
    "    tf.summary.scalar('mae', test_accuracy.result(), step=epoch)\n",
    "\n",
    "  template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test MAE: {}'\n",
    "  print (template.format(epoch+1,\n",
    "                         train_loss.result(),\n",
    "                         train_accuracy.result(),\n",
    "                         test_loss.result(),\n",
    "                         test_accuracy.result()))\n",
    "\n",
    "  # Reset metrics every epoch\n",
    "  train_loss.reset_state()\n",
    "  test_loss.reset_state()\n",
    "  train_accuracy.reset_state()\n",
    "  test_accuracy.reset_state()\n",
    "\n",
    "with fit_summary_writer.as_default():\n",
    "  tf.summary.trace_export(\n",
    "      name=\"my_func_trace\",\n",
    "      step=0,\n",
    "      profiler_outdir=str(logdir)\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.save('./data/models/mymodel.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loaded_model = keras.models.load_model('./data/models/mymodel.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SomeModel name=some_model_6, built=True>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SomeModel name=some_model_6, built=True>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000012E9303E8E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000012E9303E8E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 23644), started 0:09:25 ago. (Use '!kill 23644' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-d7788adc874f9ae8\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-d7788adc874f9ae8\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's check:\n",
    "import numpy as np\n",
    "np.testing.assert_allclose(\n",
    "    model.predict(X_test),\n",
    "    loaded_model.predict(X_test)\n",
    ")\n",
    "%tensorboard --logdir ./data/logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Launching TensorBoard..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir ./data/logs/gradient_tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
